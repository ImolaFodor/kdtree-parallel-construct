\documentclass[11pt]{article}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{graphicx}
\graphicspath{ {./images/} }


\usepackage{pgfplots}
\usepackage{graphicx}
\usepackage[skip=0.33\baselineskip]{caption}
\captionsetup[figure]{
    font=bf,
    size=normalsize,
    justification=centerlast,
    }
\usepackage[labelformat=simple]{subcaption}
    \captionsetup[subfigure]{
    font=normal,
    size=normalsize,
    justification=centerlast,
    }
\renewcommand*{\thesubfigure}{Panel \thefigure\Alph{subfigure}:}
\newcommand{\plotheight}{0.425}
\newcommand{\plotwidth}{0.7}

\title{kd-tree construction and analysis with OpenMP and OpenMPI}
\date{Deadline 28.02.2022}
\author{Imola Fodor SM3500474 \\Foundations of High Performance Computing \\University of Trieste}

\begin{document}
\maketitle
\tableofcontents

\newpage

\section{Introduction}
A K Dimensional tree (or k-d tree) is a tree data structure that is used to represent points with more than one property in a k-dimensional space. It is a convenient way to organize points by several criteria at once and it provides eg. a convenient way to search, cluster points by their overall similarity. \\ In this work a way to build and parallelize such a tree is presented.
\section{Algorithm}
The construction of the tree is done by:
\begin{itemize}
  \item Finding median/pivot by median of medians of the input array. Each section of constant length is sorted by insertion sort. 
  \item Recursively proceed on left and right portions on the left and right of the found median. Each median is a node.
  \item Terminate when length of a portion is 0. 
  \item Return root node.
\end{itemize}

The time complexity of the divide and conquer algorithm is O(nlogn) since the partition process always picks the middle element as pivot. The median of the medians is found in linear time, O(n). 
\\\\
Time complexity for partitioning n datapoints:
\begin{equation} \label{eqn}
T(n) = 2T(n/2) + \theta(n)
\end{equation}
If the partitioning would be done in a non optimal way (choosing as pivot the lowest, largest element of the array), the complexity would be O($n^2$).
\begin{algorithm}[H]
\caption{Build kD-tree}
\hspace*{\algorithmicindent} \textbf{Input} \text{arrayOfNodes} \\
\hspace*{\algorithmicindent} \textbf{Output} \text{treeRootNode}
\begin{algorithmic}[1]
\Function{BuildKDTree}{startNode, length, axis, dim}
\Statex
\If{$length = 0$}\Comment{base case}
\State return 0
\EndIf
\Statex
\State $\textit{myaxis} \gets \text{round robin approach between 0 and 1}$
\Statex
\State $\textit{medianNode} \gets \Call{MedianOfMedians}{$startNode, startNode + length -1, myaxis, len$}$
\Statex
\State $\textit{medianNode.left} \gets \Call{BuildKDTree}{$startNode, medianNode - startNode, myaxis, dim$}$
\State $\textit{medianNode.right} \gets \Call{BuildKDTree}{$startNode, startNode + length - (medianNode + 1) , myaxis, dim$}$
\State \Return \text{treeNode}
\EndFunction
\Statex
\Function{MedianOfMedians}{startNode, endNode, myaxis, length}
\If{$length < 10$}\Comment{base case}
\State \Call{InsertionSort}{$startNode, length, myaxis$}
\State $\textit{median} \gets middleElement$
\Else
\State $\text{subarrays} \gets ceiling(n/5)$
\State $\text{allocate array medians of length subarrays}$
\For{$i\gets 1, subarrays$}
\State \Call{InsertionSort}{$startNode, length, myaxis$}
\State $\textit{medians[i]} \gets middleElement$
\EndFor
\Statex
\If {$numSubarrays = high$}
\State $\textit{median} \gets \Call{MedianOfMedians}{medians, end, myaxis, length}$
\Else
\State \Call{InsertionSort}{$medians, num\_subarrays, myaxis$}
\State $\textit{median} \gets medians[middleElement]$
\EndIf
\EndIf
\State \Return \text{median}
\EndFunction
\Statex
\Procedure{InsertionSort}{startNode, length, axis}
\State \text{ similar to the sorting of playing cards in hands }
\EndProcedure
\end{algorithmic}
\end{algorithm}
\section{Implementation}

Herein the strategy used for OpenMP, OpenMP and their hybrid solution.

\subsection{OpenMP}
OpenMP is one of the application programming interfaces that facilitates the employment of a shared memory paradigm for parallelization within a node.
Below the simplified, decorated Algorithm1 with the instruction read by OpenMP during compilation.\\
\color{red}
The algorithm has not shown scaling by increasing the number of resources on 1M datapoints. The execution time reported below.\\
\textit{Results 1M datapoints}
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c| } 
 \hline
 Number of threads & 2 & 4 & 8 & 16 & 48 & 96 \\
 \hline
 Time [s] & 0.18 & 0.17 & 0.18 & 0.18	& 0.19 & 0.19 \\
 \hline
\end{tabular}
\end{center}
\color{black}
\begin{algorithm}[H]
\caption{Build kD-tree w/ OpenMP}
\hspace*{\algorithmicindent} \textbf{Input} \text{arrayOfNodes} \\
\hspace*{\algorithmicindent} \textbf{Output} \text{treeRootNode}
\begin{algorithmic}[1]
\Function{main}{}
\color{blue}
\State{\#pragma omp parallel}
\State{\#pragma omp single nowait}
\color{black}
\State{initialize random arrayOfNodes}
\State $\textit{root} \gets \Call{BuildKDTree}{$arrayOfNodes, length, 0, 2$}$
\color{blue}
\State{\#pragma omp barrier}
\color{black}
\State $print \textit{root}$
\EndFunction
\Function{BuildKDTree}{startNode, length, axis, dim}
\Statex
\If{$length = 0)$}\Comment{base case}
\State return 0
\EndIf
\Statex
\State $\textit{myaxis} \gets \text{round robin approach between 0 and 1}$
\Statex
\State $\textit{medianNode} \gets \Call{MedianOfMedians}{$startNode, startNode + length -1, myaxis, len$}$
\Statex
\color{blue}
\State{\#pragma omp task}
\color{black}
\State $\textit{medianNode.left} \gets \Call{BuildKDTree}{$leftPoints, length, myaxis, dim$}$
\color{blue}
\State{\#pragma omp task}
\color{black}
\State $\textit{medianNode.right} \gets \Call{BuildKDTree}{$rightPoints, length, myaxis, dim$}$
\State \Return \text{treeNode}
\EndFunction
\Statex
\Function{MedianOfMedians}{startNode, endNode, myaxis, length}
\If{$length < 10$}\Comment{base case}
\State \Call{InsertionSort}{$startNode, length, myaxis$}
\State $\textit{median} \gets middleElement$
\Else
\For{$i\gets 1, subarrays$}
\color{blue}
\State {\#pragma omp parallel for}
\color{black}
\State \Call{InsertionSort}{$startNode, length, myaxis$}
\State $\textit{medians[i]} \gets middleElement$
\EndFor
\Statex
\State \Call{InsertionSort}{$medians, num_subarrays, myaxis$}
\State $\textit{median} \gets medians[middleElement]$
\EndIf
\State \Return \text{median}
\EndFunction
\Statex
\algstore{bkbreak}
\end{algorithmic}
\end{algorithm}
Continuing ... 
\begin{algorithm}[h]
\begin{algorithmic}[1]
\algrestore{bkbreak}
\Procedure{InsertionSort}{startNode, length, axis}
\State \text{ similar to the sorting of playing cards in hands }
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Hybrid solution}
The hybrid solution, other than leveraging parallelization within a node, leverages also the different nodes that reside in a cluster, scaling up the solution. To achieve this, point-to-point messaging needs to be designed along the NUMA node on disposal, since each node has its own memory space.
Once a task receives it's message, each one computes the assignment on its portion of data using OpenMP threads, as under subsection OpenMP.\\\\In order for each task to get it's portion of data, rank0, the master rank, get's to find the tree nodes up until the level of the kdtree from where it is possible to assign the unique, fairly balanced, and only portions of data for each task (the left-most chunk being processed by rank 0). This approach was decided upon, to ensure load balancing and to easily reconstruct the tree, by sending the subtrees back to rank0.\\\\MPI calls are made inside parallel regions, but there is no restriction when a certain thread receives the message from the master rank, hence the $MPI\_THREAD\_MULTIPLE$ paradigm is flagged.\\\\Below the function that employs tasks, and the main function.

\begin{algorithm}[H]
\caption{Build kD-tree w/ Hybrid}
\hspace*{\algorithmicindent} \textbf{Input} \text{arrayOfNodes, numProcs, rank} \\
\hspace*{\algorithmicindent} \textbf{Output} \text{treeRootNode}
\begin{algorithmic}[1]
\Function{main}{}
\color{orange}
\State $MPI\_Init\_thread(..., MPI\_THREAD\_MULTIPLE, ...)$
\color{black}
\color{blue}
\State{\#pragma omp parallel}
\State{\#pragma omp single nowait}
\color{black}
\State{initialize random arrayOfNodes}
\If{rank = 0}
\State $\textit{root} \gets \Call{FindFirstNodes}{$arrayOfNodes, length, 0, 2, depth=0,rank = -1$}$ \Comment{rank is a pointer}
\Else
\color{orange}
\State $MPI\_Recv(length, 1, MPI\_INT, 0, 2, MPI\_COMM\_WORLD, ...)$
\State $MPI\_Recv(portion, length, MPI\_BYTE, 0, 0, MPI\_COMM\_WORLD, ...)$
\color{black}
\State $\textit{toSend} \gets \Call{BuildKDTree}{$portion, length, myaxis, 2$}$ \Comment{ideally the head of the subtree would be sent back to rank 0, for full tree construct}
\EndIf
\color{orange}
\State $MPI\_Finalize()$
\color{black}
\EndFunction
\Function{FindFirstNodes}{startNode, length, axis, dim}
\Statex
\State $\textit{myaxis} \gets \text{round robin approach between 0 and 1}$
\Statex
\If{$depth == log2(numProcs)$}\Comment{base case}
\State return 0
\EndIf
\Statex
\State $\textit{medianNode} \gets \Call{MedianOfMedians}{$startNode, startNode + length -1, myaxis, len$}$
\Statex
\color{blue}
\State{\#pragma omp task}
\color{black}
\If{$depth == log2(numProcs) - 1$}
\State $\textit{rank} \gets \text{rank} + 1$\Comment{no round robin needed}
\If{rank = 0}
\State $\textit{toSend} \gets \Call{BuildKDTree}{$leftPoints, leftLength, myaxis, 2$}$
\Else
\color{orange}
\State $MPI\_Send(leftLength, 1, MPI\_INT, rank, 2, MPI\_COMM\_WORLD)$
\State $MPI\_Send(leftPoints, leftLength, MPI\_BYTE, rank, 0, MPI\_COMM\_WORLD)$
\color{black}
\EndIf
\State $\textit{rank} \gets \text{rank} + 1$\Comment{no round robin needed}
\color{orange}
\State $MPI\_Send(rightLength, 1, MPI\_INT, rank, 2, MPI\_COMM\_WORLD)$
\State $MPI\_Send(rightPoints, rightLength, MPI\_BYTE, rank, 0, MPI\_COMM\_WORLD)$
\color{black}
\EndIf
\algstore{bkbreak}
\end{algorithmic}
\end{algorithm}
Continuing ... 
\begin{algorithm}[h]
\begin{algorithmic}[1]
\algrestore{bkbreak}
\State $\textit{depth} \gets \text{depth} + 1$
\State $\textit{medianNode.left} \gets \Call{FindFirstNodes}{$leftPoints, length, myaxis, dim, depth, rank$}$
\color{blue}
\State{\#pragma omp task}
\color{black}
\State $\textit{depth} \gets \text{depth} + 1$
\State $\textit{medianNode.right} \gets \Call{FindFirstNodes}{$rightPoints, length, myaxis, dim, depth, rank$}$
\State \Return \text{treeNode}
\EndFunction
\Statex
\end{algorithmic}
\end{algorithm}
 
\section{Performance model and scaling}
Measurements for speedup and efficiency graphs are used to acquire an indication of how well the implementation is performing in regard to some reference
implementation. As reference, the corresponding serial execution of the code is used, on the same hardware, namely, for 10k datapoints, the execution time is 0.38s.
\subsection{Hardware}
\color{red}
\begin{itemize}
\item CPU name:	Intel(R) Xeon(R) Gold 6226 CPU @ 2.70GHz
\item Sockets: 2
\item Cores per socket:	12
\item Threads per core:	2, HT on
\end{itemize}
\color{black}
\subsection{Parallel speed-up}
In order to compute the parallel speed-up of the implementation, the following formula is used:
\begin{equation} \label{eqn}
	S(P) = {T(1) / T(P)} 
\end{equation}
, where T(1) is the serial execution time, and T(P) is the parallel execution time of the same problem size, with P tasks.
\subsection{Strong scaling}
Parallel efficiency, also referred to as strong scaling, is calculated by:
\begin{equation} \label{eqn}
	E(P) = {S(P) / P} 
\end{equation}
When $S(P)=P$ it is considered a perfect speed-up. This in "real-life" is not an ultimate goal, since the code usually has parts that need to execute in a serial fashion. Ahmdal hence defined a way to model these more common, realistic implementations:
\begin{equation} \label{eqn}
	Sahm(P) = {1 /(s + (p/N)} 
\end{equation}
In case of the above described implementation, the purely serial part (s) is the initialization of the array of nodes. Furthermore, a show-stopper to a full parallelization is the part where the master rank computes the nodes up until a certain level of the tree.\\

\textit{Results 10k datapoints}
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c| } 
 \hline
 Number of procs & 2 & 4 & 8 & 16 & 32 \\
 \hline
 Time [s] & 0.39 &	0.42 & 0.42	& 0.42 & x \\
 \hline
\end{tabular}
\end{center}


\textit{Example run:}\\
\text{$mpicc -fopenmp -lm -g kdtree\_build.c -o kdtree.x$}\\
mpirun -np 2 kdtree.x\\
Start Time: 0.000000, End Time: 0.001544, Elapsed Time: 0.00154371\\
Start Time: 0.000000, End Time: 0.432807, Elapsed Time: 0.43280652\\

No further analysis has been made, since no improvement in time has been noticed as the number of procs increased.
\subsection{Weak scaling}
Gustafson instead pointed out, that in practice the sizes of problems scale with the amount of available resources.
This is called weak scaling, where the scaled speedup is calculated based on the amount of work done for a scaled problem size (in contrast to Amdahl’s law which focuses on fixed problem size). Gustafson proposed that with increased resources, the serial part remains the same, doesn't increase, even if the problem size increases.\\\\The implementation of this work does not exactly comply with the latter assumption, since the more tasks we can employ, the master rank will have a bigger amount of levels (of the tree) to compute. Nevertheless, the weak scaling analysis is done, since the possible serial part is in any case, not utterly expensive, given the max amount of tasks we can employ.
\begin{equation} \label{eqn}
	Sgus(P) = {s + p × N} 
\end{equation}
The weak efficiency can be calculated by eq.(3), changing the problem size with each change of resources.  The problem size was increased by a factor of $10$ (starting from $1k$), with each scale up in resources.
\begin{figure}[H]
\centering
\begin{subfigure}{\plotwidth\textwidth}
\centering
\includegraphics[width=\linewidth, height=\plotheight\textheight]{img_weak_scaling_efficiency}
\end{subfigure}
\end{figure}
On $Figure 4.$ it can be noted that the efficiency starts at $8\%$, would confirm that the implementation is not very suitable for leveraging large resources.
\subsection{Thread equilibrium for Hybrid solution}
To understand better the optimal number of threads to be used for the hybrid approach, further analysis is needed.
Using for the purpose the OpenMP function $omp\_get\_wtime$.
It was noted that the program, to execute on $10k$ datapoints, took slightly lower time for 2 threads, $0.39s$ whileas for larger threads the time was $>0.4s$.
\section{Conclusion}

The logic of the implementation in theory promised scaling with more tasks employed, but the timings extracted did not reflect the same.\\
\color{red}The master rank slows the computation, since it may happen that before sending the chunks to other ranks, it computes his subtree creation task.
This was addressed by programmatically directing the MPI calls to execute before the rank 0 would execute its task, but no improvement was shown in the performance.\color{black}
\\\\
\color{red}Pinning has not been specified for potential increase in performance. Profiling to better understand the time each section takes neither.\color{black}
\\\\
OpenMPI strategy could have been used to find the pivot element. In that case, rank 0 would have scattered the sections to the ranks, the ranks would have computed the insertion sort, to then send back their medians to rank 0, rank 0 gathering them.
\end{document}